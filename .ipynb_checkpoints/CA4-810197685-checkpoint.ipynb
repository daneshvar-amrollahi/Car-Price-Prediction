{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/vehicles.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we drop the rows with **price = -1**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.price != -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replacing NaN values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for col in list(df.columns):\n",
    "    print(col,\"has {0} NaN values\".format(df[col].isna().sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have NaN values in the following columns:\n",
    "1. brand\n",
    "2. mileage\n",
    "3. year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "nan_cols = [\"brand\",\"mileage\", \"year\"]\n",
    "print(df[nan_cols].mode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in nan_cols:\n",
    "    print(\"Column {} has {} NaN values\".format(col, df[col].isna().sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:,\"brand\"].fillna(\"پراید صندوق‌دار::Pride\", inplace = True)\n",
    "df.loc[:,\"mileage\"].fillna(\"200000.0\", inplace = True)\n",
    "df.loc[:,\"year\"].fillna(\"1393\", inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in nan_cols:\n",
    "    print(\"Column {} has {} NaN values\".format(col, df[col].isna().sum()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we convert the categorial values:\n",
    "1. brand\n",
    "2. category\n",
    "3. created_at\n",
    "4. description\n",
    "5. title\n",
    "6. year\n",
    "\n",
    "to numerical values so we can use the **mutual_info_regression()** method which only works with numerical values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['year'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"year\"].replace({\"<1366\": \"1366\"}, inplace=True)\n",
    "\n",
    "df['year'] = df['year'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "numerical_cols = list(df._get_numeric_data().columns)\n",
    "categorical_cols = [x for x in list(df.columns) if x not in numerical_cols]\n",
    "\n",
    "\n",
    "categorical_cols.remove('description')\n",
    "categorical_cols.remove('title')\n",
    "print(categorical_cols)\n",
    "\n",
    "ord_enc = OrdinalEncoder()\n",
    "\n",
    "df[categorical_cols] = ord_enc.fit_transform(df[categorical_cols].astype(str))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting all floats to int:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['brand'] = df['brand'].astype(int)\n",
    "df['category'] = df['category'].astype(int)\n",
    "df['created_at'] = df['created_at'].astype(int)\n",
    "df['category'] = df['category'].astype(int)\n",
    "df['mileage']= df['mileage'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we drop the categorical columns which we don't want to include in our **mutual info** calculation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['price']\n",
    "\n",
    "X = df\n",
    "\n",
    "X = X.drop(columns=['description', 'title', 'price'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.4, random_state = 0)\n",
    "mi = mutual_info_regression(X_train, y_train)\n",
    "mi = pd.Series(mi)\n",
    "mi.index = X_train.columns\n",
    "mi.sort_values(ascending = False, inplace = True)\n",
    "\n",
    "mi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.title('Mutual information with respect to features')\n",
    "mi.plot.bar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Words Exctraction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('stop_words.txt') as f:\n",
    "    ignore = [line.rstrip() for line in f]\n",
    "\n",
    "ignore = [x.strip() for x in ignore]\n",
    "print(\"Some stop words:\")\n",
    "print(ignore[30:45])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import hazm\n",
    "# from collections import Counter\n",
    "\n",
    "# words_cnt = Counter()\n",
    "\n",
    "# for sentence in df['description']:\n",
    "#     words = hazm.word_tokenize(sentence)\n",
    "#     for w in words:\n",
    "#         if w in ignore:\n",
    "#             continue\n",
    "        \n",
    "#         words_cnt[w] = words_cnt.get(w, 0) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import hazm\n",
    "# from collections import Counter\n",
    "\n",
    "# words_cnt = Counter()\n",
    "\n",
    "# for sentence in df['title']:\n",
    "#     words = hazm.word_tokenize(sentence)\n",
    "#     for w in words:\n",
    "#         if w in ignore:\n",
    "#             continue\n",
    "        \n",
    "#         words_cnt[w] = words_cnt.get(w, 0) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# most_common_words = words_cnt.most_common(50)\n",
    "# for word in most_common_words[:50]:\n",
    "#     print(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "## One Hot Encoding:\n",
    "\n",
    "We use one hot encoding for the following features:\n",
    "\n",
    "1. Brand\n",
    "2. Heavy/Light category\n",
    "3. 10 most common words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "brand_one_hot = pd.get_dummies(df['brand'], prefix='brand')\n",
    "df = df.drop(['brand'], axis = 1)\n",
    "df = pd.concat([df, brand_one_hot], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_one_hot = pd.get_dummies(df['category'], prefix = 'cat')\n",
    "df = df.drop(['category'], axis = 1)\n",
    "df = pd.concat([df, cat_one_hot], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import hazm\n",
    "\n",
    "ndf = df.drop(['description', 'title'], axis = 1)\n",
    "ndf = ndf.reset_index()\n",
    "\n",
    "\n",
    "words = ['دوگانه', 'روکش', 'تخفیف', 'نو', 'رنگ', 'وانت', 'مدادی', 'سالم', 'بیمه', 'سفید']\n",
    "\n",
    "cnt_vec = CountVectorizer(analyzer = 'word', tokenizer = hazm.word_tokenize)\n",
    "\n",
    "fit = cnt_vec.fit_transform(df['description'])\n",
    "indices = [cnt_vec.vocabulary_[word] for word in words]\n",
    "sel_fit = fit[:, indices].toarray()\n",
    "print(sel_fit.sum(axis = 0))\n",
    "ndf[words] = pd.DataFrame(sel_fit, columns = words)\n",
    "\n",
    "\n",
    "display(ndf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ndf.drop(['price', 'index'], axis = 1)\n",
    "y = ndf['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def normalize(df):\n",
    "    result = df.copy()\n",
    "    for feature_name in df.columns:\n",
    "        max_value = df[feature_name].max()\n",
    "        min_value = df[feature_name].min()\n",
    "        result[feature_name] = (df[feature_name] - min_value) / (max_value - min_value)\n",
    "    return result\n",
    "\n",
    "X = normalize(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "KNN = KNeighborsRegressor(n_neighbors = 200)\n",
    "KNN.fit(X_train, y_train)\n",
    "price_KNN = KNN.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print('RMSE:', mean_squared_error(price_KNN, y_test, squared = False))\n",
    "print('MSE:', mean_squared_error(price_KNN, y_test, squared = True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit ('base')",
   "language": "python",
   "name": "python38364bitbase7b9a83250b18425396d3e16f0fb4cd8f"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
